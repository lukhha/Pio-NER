apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "ner"
  namespace: "ner"
spec:
  predictor:
    containers:
      - name: "ner"
        image: "mlflow_dockerfile"
        ports:
          - containerPort: 8080
            protocol: TCP
        env:
          - name: PROTOCOL
            value: "v2"
