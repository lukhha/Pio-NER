{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/21 23:38:41 INFO mlflow.tracking.fluent: Experiment with name 'NER_Casestudy_Experiment2' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gen_3.8/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c1dede9d634fbea6dfbf5afa9417d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e577cd319a9f49d3b0fc2566ca35f0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d3d8fd42814b25a4197341fd30a55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9590 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gen_3.8/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee45243ddf34c1bad85b572d970029b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3846, 'learning_rate': 1.8147118769686866e-05, 'epoch': 0.28}\n",
      "{'loss': 0.2865, 'learning_rate': 1.6294237539373727e-05, 'epoch': 0.56}\n",
      "{'loss': 0.299, 'learning_rate': 1.4441356309060591e-05, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc843c98f5f4571bcc06c0ce0e41b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gen_3.8/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28697168827056885, 'eval_precision': 0.8121546961325967, 'eval_recall': 0.7859135285913529, 'eval_f1': 0.7988186650915534, 'eval_accuracy': 0.91721773205976, 'eval_runtime': 22.7655, 'eval_samples_per_second': 421.252, 'eval_steps_per_second': 26.356, 'epoch': 1.0}\n",
      "{'loss': 0.2678, 'learning_rate': 1.2588475078747453e-05, 'epoch': 1.11}\n",
      "{'loss': 0.2359, 'learning_rate': 1.0735593848434316e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2372, 'learning_rate': 8.882712618121179e-06, 'epoch': 1.67}\n",
      "{'loss': 0.2322, 'learning_rate': 7.029831387808041e-06, 'epoch': 1.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc985460f0fe4fadb064982f3831d95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gen_3.8/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29561883211135864, 'eval_precision': 0.8181602655286866, 'eval_recall': 0.8021850302185031, 'eval_f1': 0.810093896713615, 'eval_accuracy': 0.9224426483794596, 'eval_runtime': 10.1567, 'eval_samples_per_second': 944.207, 'eval_steps_per_second': 59.074, 'epoch': 2.0}\n",
      "{'loss': 0.1971, 'learning_rate': 5.176950157494905e-06, 'epoch': 2.22}\n",
      "{'loss': 0.1837, 'learning_rate': 3.324068927181768e-06, 'epoch': 2.5}\n",
      "{'loss': 0.1785, 'learning_rate': 1.4711876968686308e-06, 'epoch': 2.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61043245f48f4e7e9cd230ba0d349b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2897579073905945, 'eval_precision': 0.8211227402473834, 'eval_recall': 0.802417480241748, 'eval_f1': 0.8116623559840113, 'eval_accuracy': 0.9233406808719079, 'eval_runtime': 10.4589, 'eval_samples_per_second': 916.926, 'eval_steps_per_second': 57.368, 'epoch': 3.0}\n",
      "{'train_runtime': 724.6803, 'train_samples_per_second': 119.097, 'train_steps_per_second': 7.447, 'train_loss': 0.2458871781704535, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/gen_3.8/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5d424362f9437e98ab43cbeb04639f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'MISC', 'score': 0.9437685, 'word': 'Hu', 'start': 0, 'end': 2}, {'entity_group': 'MISC', 'score': 0.93507373, 'word': '##gging', 'start': 2, 'end': 7}, {'entity_group': 'MISC', 'score': 0.90412134, 'word': 'Face', 'start': 8, 'end': 12}, {'entity_group': 'MISC', 'score': 0.968714, 'word': 'Inc', 'start': 13, 'end': 16}, {'entity_group': 'MISC', 'score': 0.9172592, 'word': '.', 'start': 16, 'end': 17}, {'entity_group': 'PER', 'score': 0.8958597, 'word': 'is a company based in', 'start': 18, 'end': 39}, {'entity_group': 'ORG', 'score': 0.7840915, 'word': 'New York City', 'start': 40, 'end': 53}, {'entity_group': 'PER', 'score': 0.86757696, 'word': '. Its headquarters are in', 'start': 53, 'end': 78}, {'entity_group': 'MISC', 'score': 0.4847457, 'word': 'D', 'start': 79, 'end': 80}, {'entity_group': 'MISC', 'score': 0.84472, 'word': '##UM', 'start': 80, 'end': 82}, {'entity_group': 'MISC', 'score': 0.5472175, 'word': '##BO', 'start': 82, 'end': 84}, {'entity_group': 'PER', 'score': 0.94268847, 'word': ', therefore very close to the', 'start': 84, 'end': 113}, {'entity_group': 'ORG', 'score': 0.5612849, 'word': 'Manhattan Bridge', 'start': 114, 'end': 130}, {'entity_group': 'PER', 'score': 0.9838509, 'word': '.', 'start': 130, 'end': 131}]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "\n",
    "# Ensure MLflow directory exists\n",
    "mlruns_dir = '/Users/lukishyadav/Desktop/engineering/case_studies/ner_casestudy/mlruns'\n",
    "if not os.path.exists(mlruns_dir):\n",
    "    os.makedirs(mlruns_dir)\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('file:///Users/lukishyadav/Desktop/engineering/case_studies/ner_casestudy/mlruns')\n",
    "\n",
    "#experiment_id = mlflow.create_experiment('NER_Casestudy_Experiment')\n",
    "\n",
    "# Create or get the experiment\n",
    "experiment_name = \"NER_Casestudy_Experiment2\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "# Load the dataset with a specified encoding\n",
    "file_path = '/Users/lukishyadav/Desktop/engineering/case_studies/ner_casestudy/data/ner_dataset.csv'  # Replace with your file path\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Group the data by sentences\n",
    "data['Sentence #'] = data['Sentence #'].ffill()  # Fill forward to propagate sentence IDs\n",
    "sentences = data.groupby('Sentence #').apply(lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(),\n",
    "                                                                                      s['POS'].values.tolist(),\n",
    "                                                                                      s['Tag'].values.tolist())])\n",
    "# Convert the groupby object to a list of sentences\n",
    "sentences = [s for s in sentences]\n",
    "\n",
    "# Split the dataset into training, validation, and test sets (20% for test)\n",
    "train_sentences, test_sentences = train_test_split(sentences, test_size=0.20, random_state=42)\n",
    "train_sentences, val_sentences = train_test_split(train_sentences, test_size=0.25, random_state=42)  # 0.25 * 0.80 = 0.20\n",
    "\n",
    "# Convert to Hugging Face Datasets format\n",
    "def convert_to_dict(sentences):\n",
    "    words = [[word for word, pos, tag in sentence] for sentence in sentences]\n",
    "    pos_tags = [[pos for word, pos, tag in sentence] for sentence in sentences]\n",
    "    ner_tags = [[tag for word, pos, tag in sentence] for sentence in sentences]\n",
    "    return {\"tokens\": words, \"pos_tags\": pos_tags, \"ner_tags\": ner_tags}\n",
    "\n",
    "train_data = convert_to_dict(train_sentences)\n",
    "val_data = convert_to_dict(val_sentences)\n",
    "test_data = convert_to_dict(test_sentences)\n",
    "\n",
    "# Create a dataset dictionary\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_dict(train_data),\n",
    "    'validation': Dataset.from_dict(val_data),\n",
    "    'test': Dataset.from_dict(test_data)\n",
    "})\n",
    "\n",
    "# Define unique tags\n",
    "unique_tags = list(set(tag for doc in dataset_dict['train']['ner_tags'] for tag in doc))\n",
    "tag2id = {tag: id for id, tag in enumerate(unique_tags)}\n",
    "id2tag = {id: tag for tag, id in tag2id.items()}\n",
    "\n",
    "# Tokenizer\n",
    "model_checkpoint = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(tag2id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(tag2id[label[word_idx]] if True else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = dataset_dict.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Model\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(unique_tags), ignore_mismatched_sizes=True)\n",
    "model.classifier = torch.nn.Linear(model.classifier.in_features, len(unique_tags))\n",
    "model.num_labels = len(unique_tags)\n",
    "\n",
    "# Metrics\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2tag[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2tag[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "args = TrainingArguments(\n",
    "    \"test-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    use_mps_device=True\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metrics(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'MISC', 'score': 0.9437685, 'word': 'Hu', 'start': 0, 'end': 2}, {'entity_group': 'MISC', 'score': 0.93507373, 'word': '##gging', 'start': 2, 'end': 7}, {'entity_group': 'MISC', 'score': 0.90412134, 'word': 'Face', 'start': 8, 'end': 12}, {'entity_group': 'MISC', 'score': 0.968714, 'word': 'Inc', 'start': 13, 'end': 16}, {'entity_group': 'MISC', 'score': 0.9172592, 'word': '.', 'start': 16, 'end': 17}, {'entity_group': 'PER', 'score': 0.8958597, 'word': 'is a company based in', 'start': 18, 'end': 39}, {'entity_group': 'ORG', 'score': 0.7840915, 'word': 'New York City', 'start': 40, 'end': 53}, {'entity_group': 'PER', 'score': 0.86757696, 'word': '. Its headquarters are in', 'start': 53, 'end': 78}, {'entity_group': 'MISC', 'score': 0.4847457, 'word': 'D', 'start': 79, 'end': 80}, {'entity_group': 'MISC', 'score': 0.84472, 'word': '##UM', 'start': 80, 'end': 82}, {'entity_group': 'MISC', 'score': 0.5472175, 'word': '##BO', 'start': 82, 'end': 84}, {'entity_group': 'PER', 'score': 0.94268847, 'word': ', therefore very close to the', 'start': 84, 'end': 113}, {'entity_group': 'ORG', 'score': 0.5612849, 'word': 'Manhattan Bridge', 'start': 114, 'end': 130}, {'entity_group': 'PER', 'score': 0.9838509, 'word': '.', 'start': 130, 'end': 131}]\n"
     ]
    }
   ],
   "source": [
    "# Predict with the model\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\",device=device)\n",
    "sample_text = \"Hugging Face Inc. is a company based in New York City. Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge.\"\n",
    "ner_results = ner_pipeline(sample_text)\n",
    "print(ner_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
